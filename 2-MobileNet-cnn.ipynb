{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Tumor Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:41:31.194366Z",
     "iopub.status.busy": "2025-08-06T16:41:31.194101Z",
     "iopub.status.idle": "2025-08-06T16:42:40.492877Z",
     "shell.execute_reply": "2025-08-06T16:42:40.491991Z",
     "shell.execute_reply.started": "2025-08-06T16:41:31.194345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install numpy matplotlib tqdm torch torchvision torchinfo seaborn scikit-learn opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:42:45.019000Z",
     "iopub.status.busy": "2025-08-06T16:42:45.018166Z",
     "iopub.status.idle": "2025-08-06T16:42:49.386095Z",
     "shell.execute_reply": "2025-08-06T16:42:49.385430Z",
     "shell.execute_reply.started": "2025-08-06T16:42:45.018963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset:\n",
    "1. Go to 'https://www.kaggle.com/settings' and under 'API' click on create new token. A json file will be downloaded. \n",
    "2. Place that file into the same folder of the current script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the dataset from Kaggle and save it under the current folder ('/.')\n",
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "# Dataset saved in ./brain-tumor-mri-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:42:53.963381Z",
     "iopub.status.busy": "2025-08-06T16:42:53.962904Z",
     "iopub.status.idle": "2025-08-06T16:42:54.555338Z",
     "shell.execute_reply": "2025-08-06T16:42:54.554529Z",
     "shell.execute_reply.started": "2025-08-06T16:42:53.963357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'MobileNet'\n",
    "FREEZE_FEATURE_EXTRACTOR = False   # To freeze the base layers (features section)\n",
    "\n",
    "# Paths (if we download the dataset)\n",
    "TRAIN_DIR = \"./brain-tumor-mri-dataset/Training\"\n",
    "TEST_DIR = \"./brain-tumor-mri-dataset/Testing\"\n",
    "\n",
    "# Paths (on Kaggle)\n",
    "# TRAIN_DIR = \"/kaggle/input/brain-tumor-mri-dataset/Training\"\n",
    "# TEST_DIR = \"/kaggle/input/brain-tumor-mri-dataset/Testing\"\n",
    "\n",
    "# Dataset Parameters\n",
    "CATEGORIES = [\"glioma\",\"meningioma\",\"notumor\",\"pituitary\"]\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# ============= Check if CUDA is available =============\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============= PRE-TRAINED MODEL UNDER EVALUATION =============\n",
    "model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1').to(device)\n",
    "\n",
    "# ============= Training Model Parameters =============\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the *Classifier*\n",
    "Adjusting the output layer or the classifier portion of our pretrained model to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:00.140986Z",
     "iopub.status.busy": "2025-08-06T16:43:00.140669Z",
     "iopub.status.idle": "2025-08-06T16:43:00.146496Z",
     "shell.execute_reply": "2025-08-06T16:43:00.145770Z",
     "shell.execute_reply.started": "2025-08-06T16:43:00.140961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_shape = len(CATEGORIES)  # Get the length of class_names\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=False), \n",
    "    torch.nn.Linear(in_features=1280, \n",
    "                    out_features=output_shape, # same number of output units as our number of classes\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the *Feature Extractor*\n",
    "For parameters with requires_grad=False, PyTorch doesn't track gradient updates and in turn, these parameters \n",
    "won't be changed by our optimizer during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:02.107295Z",
     "iopub.status.busy": "2025-08-06T16:43:02.106550Z",
     "iopub.status.idle": "2025-08-06T16:43:02.111589Z",
     "shell.execute_reply": "2025-08-06T16:43:02.110713Z",
     "shell.execute_reply.started": "2025-08-06T16:43:02.107259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Doing the freezing\n",
    "if FREEZE_FEATURE_EXTRACTOR:\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:04.469194Z",
     "iopub.status.busy": "2025-08-06T16:43:04.468322Z",
     "iopub.status.idle": "2025-08-06T16:43:04.866181Z",
     "shell.execute_reply": "2025-08-06T16:43:04.865379Z",
     "shell.execute_reply.started": "2025-08-06T16:43:04.469154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Printing the Final Model\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, IMG_SIZE, IMG_SIZE),\n",
    "        col_names=[\"num_params\", \"trainable\"],\n",
    "        col_width=15,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:11.746913Z",
     "iopub.status.busy": "2025-08-06T16:43:11.746172Z",
     "iopub.status.idle": "2025-08-06T16:43:22.027228Z",
     "shell.execute_reply": "2025-08-06T16:43:22.026515Z",
     "shell.execute_reply.started": "2025-08-06T16:43:11.746879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.95, 1.05)),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "test_dataset_clean = datasets.ImageFolder(TEST_DIR, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader_clean = DataLoader(test_dataset_clean, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN (*on the GPU*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:24.501218Z",
     "iopub.status.busy": "2025-08-06T16:43:24.500585Z",
     "iopub.status.idle": "2025-08-06T16:43:24.505523Z",
     "shell.execute_reply": "2025-08-06T16:43:24.504761Z",
     "shell.execute_reply.started": "2025-08-06T16:43:24.501192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:26.643642Z",
     "iopub.status.busy": "2025-08-06T16:43:26.643333Z",
     "iopub.status.idle": "2025-08-06T16:43:26.650702Z",
     "shell.execute_reply": "2025-08-06T16:43:26.649988Z",
     "shell.execute_reply.started": "2025-08-06T16:43:26.643620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training function with progress bar\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch_num, total_epochs):\n",
    "    # Set model to training mode - enables dropout, batch norm updates, etc.\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize tracking variables for this epoch\n",
    "    running_loss = 0.0  # Accumulate loss across batches\n",
    "    correct = 0         # Count correct predictions\n",
    "    total = 0           # Count total samples processed\n",
    "    \n",
    "    # Create progress bar for training batches\n",
    "    train_bar = tqdm(dataloader, desc=f'Training Epoch {epoch_num}/{total_epochs}', leave=False, dynamic_ncols=True)\n",
    "    \n",
    "    # Iterate through batches in the training dataset\n",
    "    for batch_idx, (data, target) in enumerate(train_bar):\n",
    "        # Move data and labels to GPU/CPU device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Clear gradients from previous iteration (PyTorch accumulates gradients by default)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute model predictions\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate loss between predictions and true labels\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass: compute gradients via backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters using computed gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics for this batch\n",
    "        running_loss += loss.item()  # .item() extracts scalar value from tensor\n",
    "        \n",
    "        # Get predicted class (index of maximum logit)\n",
    "        _, predicted = torch.max(output.data, 1)  # Returns (max_values, indices)\n",
    "        \n",
    "        # Update counters\n",
    "        total += target.size(0)  # Add batch size to total count\n",
    "        correct += (predicted == target).sum().item()  # Count correct predictions\n",
    "        \n",
    "        # Update progress bar with current metrics\n",
    "        current_acc = 100. * correct / total\n",
    "        current_loss = running_loss / (batch_idx + 1)  # Average loss so far\n",
    "        train_bar.set_postfix({\n",
    "            'Loss': f'{current_loss:.4f}',\n",
    "            'Acc': f'{current_acc:.2f}%'\n",
    "        })\n",
    "    \n",
    "    # Calculate final epoch metrics\n",
    "    epoch_loss = running_loss / len(dataloader)  # Average loss across all batches\n",
    "    epoch_acc = 100. * correct / total          # Final accuracy percentage\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:43:29.123810Z",
     "iopub.status.busy": "2025-08-06T16:43:29.123529Z",
     "iopub.status.idle": "2025-08-06T16:47:23.232251Z",
     "shell.execute_reply": "2025-08-06T16:47:23.231226Z",
     "shell.execute_reply.started": "2025-08-06T16:43:29.123788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch + 1, EPOCHS)\n",
    "    \n",
    "    # Calculate time for this epoch\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "# Final results\n",
    "end_time = time.time()\n",
    "full_finetune_times = end_time - start_time\n",
    "\n",
    "# Save final model\n",
    "model_name_ext = model_name + '.pth'\n",
    "torch.save(model.state_dict(), model_name_ext)\n",
    "\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(f\"Total training time: {full_finetune_times:.2f} seconds ({full_finetune_times/60:.2f} minutes)\")\n",
    "print(f\"Average time per epoch: {full_finetune_times/EPOCHS:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model (*on the CPU!*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following snippet of code the '.cpu()' call moves a PyTorch tensor from the GPU back to the CPU.\n",
    "\n",
    "PyTorch tensors must be on the CPU to be converted into NumPy arrays using .numpy(), because .numpy() only works on CPU tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:47:33.900038Z",
     "iopub.status.busy": "2025-08-06T16:47:33.899730Z",
     "iopub.status.idle": "2025-08-06T16:47:39.139990Z",
     "shell.execute_reply": "2025-08-06T16:47:39.139200Z",
     "shell.execute_reply.started": "2025-08-06T16:47:33.900008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader_clean:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        # Collect confidence scores\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        max_probs = torch.max(probs, dim=1)[0]\n",
    "\n",
    "# Compute test loss and accuracy\n",
    "clean_test_loss = running_loss / len(test_loader_clean)\n",
    "clean_test_acc = 100. * correct / total\n",
    "print(f'Test Loss: {clean_test_loss:.4f}, Test Acc: {clean_test_acc:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:51:03.689627Z",
     "iopub.status.busy": "2025-08-06T16:51:03.688954Z",
     "iopub.status.idle": "2025-08-06T16:51:03.906599Z",
     "shell.execute_reply": "2025-08-06T16:51:03.905833Z",
     "shell.execute_reply.started": "2025-08-06T16:51:03.689600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',xticklabels=CATEGORIES, yticklabels=CATEGORIES, annot_kws={'size': 17})\n",
    "\n",
    "plt.xlabel('Predicted Label', fontweight='bold', fontsize=20)\n",
    "plt.ylabel('True Label', fontweight='bold', fontsize=20)\n",
    "plt.xticks(fontsize=15) \n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:51:06.522894Z",
     "iopub.status.busy": "2025-08-06T16:51:06.522152Z",
     "iopub.status.idle": "2025-08-06T16:51:06.534949Z",
     "shell.execute_reply": "2025-08-06T16:51:06.534144Z",
     "shell.execute_reply.started": "2025-08-06T16:51:06.522868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nTest - Classification Report:\")\n",
    "report = classification_report(all_targets, all_preds, target_names=CATEGORIES)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2689882,
     "datasetId": 1608934,
     "sourceId": 2645886,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
